<!doctype html>
<html lang="en">
<head>
  <!-- Required meta tags -->
  <meta charset="ISO-8859-1">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

  <style>
header {
  padding: 156px 0 100px;
}
section {
  padding: 150px 0;
}
.abstract {
  font-style: italic;
}
#bibtex {
  resize: none;
  height: 230px;
  overflow: hidden;
}
.card-body {
  font-size: 1rem;
  line-height: 1.5;
}
.card-body .card-text.collapse:not(.show) {
  display: block;
  height: 3rem;
  overflow: hidden;
}
.card-body .card-text.collapsing {
  height: 3rem;
}
.card-body .more.collapsed::after {
  content: '+ Show More';
}
.card-body .more:not(.collapsed)::after {
  content: '- Show Less';
}
.card-body .pubs.collapsed::after {
  content: '+ Show Publications';
}
.card-body .pubs:not(.collapsed)::after {
  content: '- Hide Publications';
}
  </style>

  <!-- Optional JavaScript -->
  <!-- jQuery first, then Popper.js, then Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

  <title>Ontology-based Approaches to Robot Autonomy</title>
</head>

<body id="page-top">

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
    <div class="container">
      <!--
      <a class="navbar-brand js-scroll-trigger" href="#page-top">Start Bootstrap</a>
      -->
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#about">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#projects">Projects</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#cogs">Capabilities</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#contact">Contact</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <header class="bg-primary text-white">
    <div class="container text-center">
      <h1>Ontology-based Approaches to Robot Autonomy</h1>
      <p class="lead">A landscape of current research</p>
    </div>
  </header>

  <section id="about">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2>About this page</h2>
          <!-- -->
          <!-- TODO: add reference to (Langley, Laird, and S. Rogers 2009).-->
          <p class="lead">This page presents different projects that use explicit knowledge encoded in an ontology to support some aspects of robot autonomy. Robots may reach different levels of autonomy depending on what restrictions their architecture imposes, and what type of cognitive capabilities it supports. It is hard, however, to pinpoint a definition of autonomy. It is more common to list features that a cognitive system needs to address, such as:</p>
          <ul>
            <li>recognition and categorization;</li>
            <li>decision making and choice;</li>
            <li>perception and situation assessment;</li>
            <li>prediction and monitoring;</li>
            <li>problem solving and planning;</li>
            <li>reasoning and belief maintenance;</li>
            <li>execution and action; and</li>
            <li>remembering, reflection, and learning.</li>
          </ul>
          <!-- -->
          <!-- TODO: add link to KER -->
          <p class="lead">This page has been created to summarize the findings of the literature review paper entitled <em>"A Review and Comparison of Ontology-based Approaches to Robot Autonomy"</em> that was published at the Knowledge Engineering Review journal in 2019.</p>
          <p class="lead">This is the abstract of the paper: <div class="abstract">Within the next decades, robots will need to be able to execute a large variety of tasks autonomously in a large variety of environments. To relax the resulting programming effort, a knowledge-enabled approach to robot programming can be adopted to organize information in re-usable knowledge pieces. However, for the ease of re-use, there needs to be an agreement on the meaning of terms. A common approach is to represent these terms using ontology languages that conceptualize the respective domain. In this work, we will review projects that use ontologies to support robot autonomy. We will systematically search for projects that fulfill a set of inclusion criteria, and compare them with each other with respect to the scope of their ontology, what types of cognitive capabilities are supported by the use of ontologies, and which is their application domain.</div></p>
          <p class="lead">Please use the following bibtex entry for citing us:<br><br>
          <!-- TODO: update the bibtex entry -->
          <textarea id="bibtex" class="form-control rounded" readonly>
@article{olivares19ker,
  author = {Olivares-Alarcos, Alberto and Be{\ss}ler, Daniel and Khamis, Alaa and Goncalves, Paulo and Habib, Maki and Bermejo, Julita and Barreto, Marcos and Diab, Mohammed and Rosell, Jan and Quintas, Jo\~ao and Olszewska, Joanna and Nakawala, Hirenkumar and Pignaton, Edison and Gyrard, Amelie and Borgo, Stefano and Aleny\`a, Guillem and Beetz, Michael and Li, Howard},
  title = {A Review and Comparison of Ontology-based Approaches to Robot Autonomy}, 
  journal={The Knowledge Engineering Review}, publisher={Cambridge University Press}, 
  pages={e29}, volume={34}, DOI={10.1017/S0269888919000237}, year = {2019}
}
          </textarea>
          </p>
        </div>
      </div>
    </div>
  </section>

  <section id="projects">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2>Projects</h2>
          <p>In total, six frameworks/projects have been subject of study in our review. For each of them, their underlying principles and foundations are discussed, as well as what application domain the system was designed for. We also describe how the frameworks evolved over time, and what impact they have had so far. The selection of the presented projects has been done based on the selection criteria presented within the article. To the best of our knowledge, we have included all projects that satisfy the criteria.</p>

          <div class="card w-100" id="ORO-card">
            <div class="card-body">
              <h5 class="card-title">ORO (2010-)</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">ORO</h6> -->
              <p class="card-subtitle mb-2 text-muted">LAAS-CNRS, France</p>
              <p class="card-text collapse" id="ORO" aria-expanded="false">ORO is a project focused on the implementation of a common representation frameworkfor autonomous robots with special emphasizes on human-robot interaction. The proposed framework was meant to enhance robotâs interactionwith complex and human-inhabited environments, were robots are expected to exhibit advancedcognitive skills, such as: object recognition, natural language interaction, task planning withpossible dynamic re-planning, ability to cooperate with other robots or humans, etc.</p>
              <a role="button" class="card-link more collapsed" data-toggle="collapse" href="#ORO" aria-expanded="false" aria-controls="ORO"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#ORO-pubs" aria-expanded="false" aria-controls="ORO-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="ORO-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Ros, Raquel et al. (2010). Which one? grounding the referent based on efficient human-robot interaction. In: International Symposium in Robot and Human Interactive Communication (RO-MAN). IEEE, pp. 570-575.

                    <a href="#cog-rec-card">cog-rec</a>

                    <a href="#cog-perc-card">cog-perc</a>

                    <a href="#cog-inter-card">cog-inter</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Sisbot, E Akin, Raquel Ros, and Rachid Alami (2011). Situation assessment for human-robot interactive object manipulation. In: International Symposium in Robot and Human Interactive Communication (RO-MAN). IEEE, pp. 15-20

                    <a href="#cog-perc-card">cog-perc</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Warnier, Mathieu et al. (2012). When the robot puts itself in your shoes. Managing and exploiting human and robot beliefs. In: International Symposium on Robot and Human Interactive Communication (RO-MAN). IEEE, pp. 948-954.

                    <a href="#cog-reas-card">cog-reas</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Lemaignan, Severin, Raquel Ros, Rachid Alami, et al. (2011). What are you talking about? grounding dialogue in a perspective-aware robotic architecture. In: International Symposium on Robot and Human Interactive Communication (RO-MAN). IEEE, pp. 107-112.

                    <a href="#cog-inter-card">cog-inter</a>

                </li>

              </ul><br>

              <a class="card-link" href="https://www.openrobots.org/wiki/oro-server/">Project Website</a>


              <a class="card-link" href="https://www.laas.fr/public/">Maintainer Website</a>


              <a class="card-link" href="https://www.openrobots.org/wiki/oro-ontology">Source Code</a>

            </div>
          </div><br>

          <div class="card w-100" id="KnowRob-card">
            <div class="card-body">
              <h5 class="card-title">KnowRob (2009-)</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">KnowRob</h6> -->
              <p class="card-subtitle mb-2 text-muted">Institute for Artificial Intelligence, University of Bremen</p>
              <p class="card-text collapse" id="KnowRob" aria-expanded="false">KnowRob is a knowledge processing system that combines knowledge representation and reasoning methods with techniques for acquiring knowledge and for grounding the knowledge in a physical system and can serve as a common semantic framework for integrating information from different sources. KnowRob combines static encyclopedic knowledge, common-sense knowledge, task descriptions, environment models, object information and information about observed actions that has been acquired from various sources (manually axiomatized, derived from observations, or imported from the web). It supports different deterministic and probabilistic reasoning mechanisms, clustering, classification and segmentation methods, and includes query interfaces as well as visualization tools.</p>
              <a role="button" class="card-link more collapsed" data-toggle="collapse" href="#KnowRob" aria-expanded="false" aria-controls="KnowRob"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#KnowRob-pubs" aria-expanded="false" aria-controls="KnowRob-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="KnowRob-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Beßler, Daniel, Robert Porzel, et al. (2019). Foundational Models for Manipulation Activity Parsing. In: Augmented Reality and Virtual Reality -- Changing Realities in a Dynamic World. Ed. by Timothy Jung, M. Claudia tom Dieck, and Philipp A. Rauschnabel. 978-3-030-37869-1. Springer. isbn: 978-3-030-37869-1.

                    <a href="#cog-rec-card">cog-rec</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Beetz, Michael, Ferenc Balint-Benczedi, et al. (2015). RoboSherlock: Unstructured information processing for robot perception. In: IEEE International Conference on Robotics and Automation (ICRA). pp. 1549--1556.

                    <a href="#cog-perc-card">cog-perc</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Tenorth, Moritz and Michael Beetz (2012). A unified representation for reasoning about robot actions, processes, and their effectson objects. In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, pp. 1351-1358

                    <a href="#cog-pred-card">cog-pred</a>

                    <a href="#cog-prob-card">cog-prob</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Beßler, Daniel, Mihai Pomarlan, and Michael Beetz (2018). OWL-enabled Assembly Planningfor Robotic Agents. In: Proceedings of the 2018 International Conference on Autonomous Agents. AAMAS &#39;18. Finalist for the Best Robotics Paper Award. Stockholm, Sweden.

                    <a href="#cog-prob-card">cog-prob</a>

                    <a href="#cog-reas-card">cog-reas</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Tenorth, Moritz, Lars Kunze, et al. (2010). KNOWROB-MAP - Knowledge-LinkedSemantic Object Maps. In:10th IEEE-RAS International Conference on Humanoid Robots. Nashville, TN, USA, pp. 430-435.

                    <a href="#cog-reas-card">cog-reas</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Beetz, Michael, Lorenz Mosenlechner, and Moritz Tenorth (2010). CRAM - A Cognitive RobotAbstract Machine for everyday manipulation in human environments. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE,pp. 1012-1017.

                    <a href="#cog-exec-card">cog-exec</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Tenorth, Moritz, Georg Bartels, and Michael Beetz (2014). Knowledge-based Specification of Robot Motions. In: Proc. of the European Conference on Artificial Intelligence (ECAI).

                    <a href="#cog-exec-card">cog-exec</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Tenorth, Moritz, Daniel Nyga, and Michael Beetz (2010). Understanding and ExecutingInstructions for Everyday Manipulation Tasks from the World Wide Web. In: IEEE International Conference on Robotics and Automation (ICRA). Anchorage, AK, USA, pp. 1486-1491.

                    <a href="#cog-exec-card">cog-exec</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Yazdani, Fereshta et al. (2018). Cognition-enabled Framework for Mixed Human-Robot Rescue Team. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE. Madrid, Spain.

                    <a href="#cog-inter-card">cog-inter</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Beetz, Michael, Daniel Beßler, Andrei Haidu, et al. (2018). KnowRob 2.0 - A 2nd Generation Knowledge Processing Framework for Cognition-enabled Robotic Agents. In: IEEE International Conference on Robotics and Automation (ICRA).

                    <a href="#cog-remem-card">cog-remem</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Beetz, Michael, Moritz Tenorth, and Jan Winkler (2015). Open-EASE - A Knowledge Processing Service for Robots and Robotics/AI Researchers. In: IEEE International Conference on Robotics and Automation (ICRA). Finalist for the Best Cognitive Robotics Paper Award. Seattle, Washington, USA.

                    <a href="#cog-remem-card">cog-remem</a>

                </li>

              </ul><br>

              <a class="card-link" href="http://knowrob.org">Project Website</a>


              <a class="card-link" href="http://ai.uni-bremen.de">Maintainer Website</a>


              <a class="card-link" href="https://github.com/knowrob/knowrob">Source Code</a>

            </div>
          </div><br>

          <div class="card w-100" id="OROSU-card">
            <div class="card-body">
              <h5 class="card-title">OROSU (2013-)</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">OROSU</h6> -->
              <p class="card-subtitle mb-2 text-muted">Polytechnic Institute of Castelo Branco, Portugal</p>
              <p class="card-text collapse" id="OROSU" aria-expanded="false">An Ontology for Robotic Orthopedic Surgery (OROSU) was developed and then applied for hip resurfacing surgery (e.g., for trimming the femoral head). In this scope, the main goal of the research, related to ontologies, was to build a knowledge-based framework for this surgical scenario, along with a formal definition of components and actions to be performed during the surgery. The developed ontology was partially based on the 1872-2015 - IEEE Standard Ontologies for Robotics and Automation. The work was developed under the HIPROB and ECHORD projects, funded by the Portuguese Science Foundation and the EU-FP7, respectively. The framework is among the first to integrate robotic ontologies in the domain of surgical robotics.</p>
              <a role="button" class="card-link more collapsed" data-toggle="collapse" href="#OROSU" aria-expanded="false" aria-controls="OROSU"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#OROSU-pubs" aria-expanded="false" aria-controls="OROSU-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="OROSU-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Goncalves, Paulo JS and Pedro MB Torres (2015). Knowledge representation applied to robotic orthopedic surgery. In: Robotics and Computer-Integrated Manufacturing. 33, pp. 90-99.

                    <a href="#cog-exec-card">cog-exec</a>

                </li>

              </ul><br>

              <a class="card-link" href="http://www.echord.info/wikis/website/hiprob.html">Project Website</a>


              <a class="card-link" href="https://www.ipcb.pt/">Maintainer Website</a>


              <a class="card-link" href="https://github.com/pbsgoncalves/OROSU">Source Code</a>

            </div>
          </div><br>

          <div class="card w-100" id="PMK-card">
            <div class="card-body">
              <h5 class="card-title">PMK (2019-)</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">PMK</h6> -->
              <p class="card-subtitle mb-2 text-muted">Institute of Industrial and Control Engineering (IOC), Polytechnic University of Catalonia (UPC)</p>
              <p class="card-text collapse" id="PMK" aria-expanded="false">Perception and Manipulation knowledge framework (PMK) presents a standardized ontology framework for autonomous robot perception and manipulation, which follows the IEEE standards 1872 of representing knowledge for the robotic domain. Moreover, an inference mechanism for reasoning over the knowledge is included, which enhances the planning of manipulation tasks. A perception module can be integrated with the framework to capture a rich semantic description of the scene, knowledge about the physical behavior of the objects, and reasoning about the potential manipulation actions. The reasoning scope of PMK is divided into four parts: reasoning for perception, the reasoning for object features, the reasoning for a situation, and reasoning for planning.</p>
              <a role="button" class="card-link more collapsed" data-toggle="collapse" href="#PMK" aria-expanded="false" aria-controls="PMK"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#PMK-pubs" aria-expanded="false" aria-controls="PMK-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="PMK-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Diab, Mohammed, Aliakbar Akbari, Jan Rosell, et al. (2017). An ontology framework for physics-based manipulation planning. In: Iberian Robotics conference. Springer.

                    <a href="#cog-dec-card">cog-dec</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Diab, Mohammed, Aliakbar Akbari, Muhayy Ud Din, et al. (2019). PMK-A Knowledge Processing Framework for Autonomous Robotics Perception and Manipulation. In: Sensors. 19. 5.

                    <a href="#cog-dec-card">cog-dec</a>

                    <a href="#cog-perc-card">cog-perc</a>

                    <a href="#cog-reas-card">cog-reas</a>

                </li>

              </ul><br>

              <a class="card-link" href="https://github.com/MohammedDiab1/PMK">Project Website</a>


              <a class="card-link" href="https://ioc.upc.edu/en">Maintainer Website</a>


              <a class="card-link" href="https://github.com/MohammedDiab1/PMK">Source Code</a>

            </div>
          </div><br>

          <div class="card w-100" id="CARESSES-card">
            <div class="card-body">
              <h5 class="card-title">CARESSES (2017-)</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">CARESSES</h6> -->
              <p class="card-subtitle mb-2 text-muted">Department of Informatics, Bioengineering, Robotics, and Systems Engineering, University of Genoa</p>
              <p class="card-text collapse" id="CARESSES" aria-expanded="false">CARESSES is an international, multidisciplinary project whose goal is to design the first robots that can assist older people and adapt to the culture of the individual they are taking care of. The robots will help the users in many ways including reminding them to take their medication, encouraging them to keep active, helping them keep in touch with family and friends. Each action will be performed with attention to the older personâs customs, cultural practices and individual preferences.</p>
              <a role="button" class="card-link more collapsed" data-toggle="collapse" href="#CARESSES" aria-expanded="false" aria-controls="CARESSES"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#CARESSES-pubs" aria-expanded="false" aria-controls="CARESSES-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="CARESSES-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Menicatti, Roberto, Barbara Bruno, and Antonio Sgorbissa (2017). Modelling the influence of cultural information on vision-based human home activity recognition. In: International conference on ubiquitous robots and ambient intelligence (URAI). IEEE, pp. 32-38.

                    <a href="#cog-rec-card">cog-rec</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Bruno, Barbara, Carmine Tommaso Recchiuto, et al. (2019). Knowledge Representation for Culturally Competent Personal Robots: Requirements, Design Principles, Implementation, and Assessment. In: International Journal of Social Robotics11.3, pp. 515-538.

                    <a href="#cog-dec-card">cog-dec</a>

                    <a href="#cog-reas-card">cog-reas</a>

                    <a href="#cog-inter-card">cog-inter</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Sgorbissa, Antonio et al. (2018). Encoding guidelines for a culturally competent robot for elderly care. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, pp. 1988-1995

                    <a href="#cog-exec-card">cog-exec</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Bruno, Barbara, Roberto Menicatti, et al. (2018). Culturally-Competent Human-Robot Verbal Interaction. In: International Conference on Ubiquitous Robots (UR). IEEE,pp. 388-395.

                    <a href="#cog-inter-card">cog-inter</a>

                </li>

              </ul><br>

              <a class="card-link" href="http://caressesrobot.org/en/">Project Website</a>


              <a class="card-link" href="https://www.dibris.unige.it/en/">Maintainer Website</a>


              <a class="card-link" href="https://github.com/Suman7495/Robot-Navigation-for-Vision-Based-HAR/tree/master/Vision%20Based%20Navigation%20for%20HAR/ontology">Source Code</a>

            </div>
          </div><br>

          <div class="card w-100" id="ROSETTA-card">
            <div class="card-body">
              <h5 class="card-title">ROSETTA (2013-)</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">ROSETTA</h6> -->
              <p class="card-subtitle mb-2 text-muted">Computer Science, Faculty of Engineering of Lund University</p>
              <p class="card-text collapse" id="ROSETTA" aria-expanded="false">ROSETTA stands for RObot control for Skilled ExecuTion of Tasks in natural interaction with humans; based on Autonomy, cumulative knowledge and learning. It consists of a set of ontologies of robot skills implemented with the goal to create an intelligent support system for reconfiguration and adaptation of robot-based manufacturing cells. Along the years, the ontology has been used to enhance cognitive abilities of robots that are required to plan and execute assembly tasks, robot programming, and skill reusability in industrial scenarios.</p>
              <a role="button" class="card-link more collapsed" data-toggle="collapse" href="#ROSETTA" aria-expanded="false" aria-controls="ROSETTA"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#ROSETTA-pubs" aria-expanded="false" aria-controls="ROSETTA-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="ROSETTA-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Stenmark, Maj, Jacek Malec, and Andreas Stolt (2015). From high-level task descriptions toexecutable robot code. In: Intelligent Systems. Springer, pp. 189-202.

                    <a href="#cog-exec-card">cog-exec</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Stenmark, Maj, Mathias Haage, et al. (2018). Supporting semantic capture during kinestheticteaching of collaborative industrial robots. In: International Journal of Semantic Computing. 12.01, pp. 167-186.

                    <a href="#cog-remem-card">cog-remem</a>

                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Topp, Elin A et al. (2018). Ontology-Based Knowledge Representation for Increased Skill Reusability in Industrial Robots. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, pp. 5672-5678.

                    <a href="#cog-remem-card">cog-remem</a>

                </li>

              </ul><br>

              <a class="card-link" href="http://www.fp7rosetta.org/">Project Website</a>


              <a class="card-link" href="http://cs.lth.se/english/">Maintainer Website</a>


              <a class="card-link" href="https://github.com/jacekmalec/Rosetta_ontology">Source Code</a>

            </div>
          </div><br>

        </div>
      </div>
    </div>
  </section>

  <section id="cogs" class="bg-light">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2>Cognitive Capabilities</h2>
          <p>The scope of reasoning is our second classification criterion for the comparison between ontology-based approaches in autonomous robotics. It consists of a categorization of nine ontology-based reasoning tasks that are in particular relevant for autonomous robotics, and that have been considered in previous works.</p>

          <div class="card w-100" id="cog-rec-card">
            <div class="card-body">
              <h5 class="card-title">Recognition and Categorization</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">Card subtitle</h6> -->
              <p class="card-text collapse" id="cog-rec" aria-expanded="false">For the purpose of establishing a contact between its environment and its knowledge, a robot must be able to recognize events or situations (static and dynamic) and categorize them as named instances of already known patterns. For instance, let’s consider a collaborative industrial robotic arm which picks pieces from a conveyor and places them on a table where a human operator can access to. The robot must recognize and cateogorize the conveyor and the different pieces to manipulate (static), as well as a the human collaborator’s movements and actions (dynamic). Both, recognition and categorization, operate on the output generated by perception systems and often are seen as a unique capability. Nevertheless, they are addressed separately because both can operate on abstract mental structures. In order to support recognition and categorization, a cognitive architecture shall provide a form to represent patterns and situations in memory.</p>
              <a role="button" class="more collapsed" data-toggle="collapse" href="#cog-rec" aria-expanded="false" aria-controls="cog-rec"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#cog-rec-pubs" aria-expanded="false" aria-controls="cog-rec-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="cog-rec-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Ros, Raquel et al. (2010). Which one? grounding the referent based on efficient human-robot interaction. In: International Symposium in Robot and Human Interactive Communication (RO-MAN). IEEE, pp. 570-575.
                    <a href="#ORO-card">ORO</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Beßler, Daniel, Robert Porzel, et al. (2019). Foundational Models for Manipulation Activity Parsing. In: Augmented Reality and Virtual Reality -- Changing Realities in a Dynamic World. Ed. by Timothy Jung, M. Claudia tom Dieck, and Philipp A. Rauschnabel. 978-3-030-37869-1. Springer. isbn: 978-3-030-37869-1.
                    <a href="#KnowRob-card">KnowRob</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Menicatti, Roberto, Barbara Bruno, and Antonio Sgorbissa (2017). Modelling the influence of cultural information on vision-based human home activity recognition. In: International conference on ubiquitous robots and ambient intelligence (URAI). IEEE, pp. 32-38.
                    <a href="#CARESSES-card">CARESSES</a>
                </li>

              </ul>
            </div>
          </div><br>

          <div class="card w-100" id="cog-dec-card">
            <div class="card-body">
              <h5 class="card-title">Decision Making and Choice</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">Card subtitle</h6> -->
              <p class="card-text collapse" id="cog-dec" aria-expanded="false">An autonomous robot requires the ability to choose among several alternatives, which usually is considered together with the recognition and categorization problem in a recognize-act cycle. Nonetheless, we consider the capability of decision making independently. It is important not to mistake this capability with planning, whose focus is on the achievement of a goal and it will be explained later. For example, a collaborative robot would apply decision making to choose between moving or not when the operator is close, while planning would be used to find the sequence or sequences of actions which are likely to lead to a successful collaborative task. A cognitive architecture should be able to represent the different choices in a format the robot understands. Indeed, that representation would also be used to improve the decision making through learning.</p>
              <a role="button" class="more collapsed" data-toggle="collapse" href="#cog-dec" aria-expanded="false" aria-controls="cog-dec"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#cog-dec-pubs" aria-expanded="false" aria-controls="cog-dec-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="cog-dec-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Diab, Mohammed, Aliakbar Akbari, Jan Rosell, et al. (2017). An ontology framework for physics-based manipulation planning. In: Iberian Robotics conference. Springer.
                    <a href="#PMK-card">PMK</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Diab, Mohammed, Aliakbar Akbari, Muhayy Ud Din, et al. (2019). PMK-A Knowledge Processing Framework for Autonomous Robotics Perception and Manipulation. In: Sensors. 19. 5.
                    <a href="#PMK-card">PMK</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Bruno, Barbara, Carmine Tommaso Recchiuto, et al. (2019). Knowledge Representation for Culturally Competent Personal Robots: Requirements, Design Principles, Implementation, and Assessment. In: International Journal of Social Robotics11.3, pp. 515-538.
                    <a href="#CARESSES-card">CARESSES</a>
                </li>

              </ul>
            </div>
          </div><br>

          <div class="card w-100" id="cog-perc-card">
            <div class="card-body">
              <h5 class="card-title">Perception and Situation Assessment</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">Card subtitle</h6> -->
              <p class="card-text collapse" id="cog-perc" aria-expanded="false">The environment where the robot exists, must be sensed, perceived and interpreted. First, the robot senses its surroundings through possibly muti-modal sensors. Then, using the gathered information and relying on recognition and categorization, discussed earlier, and on inferential mechanisms, which will be covered shortly, the robot is able to perceive the environmental entities (e.g. objects and events). Finally, the situation assessment takes place when the perceived objects and events are interpreted. Following with the example used before, a collaborative industrial robot would look at the conveyor, the pieces and at the operator&#39;s movements to sense the environment. The pieces, their poses and other information would be recognized and categorized in order to assess the environmental situation so that the robot could, for example, interpret that an approaching piece should be picked. Just as occurred with previous cognitive capabilities, the inherent knowledge of the whole process must be represented in a manner the robot understands. Note that the representation requires memory, a resource which is often limited. Hence, the notion of attention emerges, meaning that the robot not only has to perceive but also it could be asked to decide to focus only on a specific region of the environment.</p>
              <a role="button" class="more collapsed" data-toggle="collapse" href="#cog-perc" aria-expanded="false" aria-controls="cog-perc"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#cog-perc-pubs" aria-expanded="false" aria-controls="cog-perc-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="cog-perc-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Ros, Raquel et al. (2010). Which one? grounding the referent based on efficient human-robot interaction. In: International Symposium in Robot and Human Interactive Communication (RO-MAN). IEEE, pp. 570-575.
                    <a href="#ORO-card">ORO</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Sisbot, E Akin, Raquel Ros, and Rachid Alami (2011). Situation assessment for human-robot interactive object manipulation. In: International Symposium in Robot and Human Interactive Communication (RO-MAN). IEEE, pp. 15-20
                    <a href="#ORO-card">ORO</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Beetz, Michael, Ferenc Balint-Benczedi, et al. (2015). RoboSherlock: Unstructured information processing for robot perception. In: IEEE International Conference on Robotics and Automation (ICRA). pp. 1549--1556.
                    <a href="#KnowRob-card">KnowRob</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Diab, Mohammed, Aliakbar Akbari, Muhayy Ud Din, et al. (2019). PMK-A Knowledge Processing Framework for Autonomous Robotics Perception and Manipulation. In: Sensors. 19. 5.
                    <a href="#PMK-card">PMK</a>
                </li>

              </ul>
            </div>
          </div><br>

          <div class="card w-100" id="cog-pred-card">
            <div class="card-body">
              <h5 class="card-title">Prediction and Monitoring</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">Card subtitle</h6> -->
              <p class="card-text collapse" id="cog-pred" aria-expanded="false">Prediction is a cognitive capability which requires the representation in memory of a model (e.g. ontology-based) of the environment, the actions that can take place and their effects. Therefore, the robot could predict future events and situations which did not occur yet by means of a proper mechanism which utilizes the representation. Applied to the collaborative robotics&#39; example, it would be possible for the robot to predict the operator&#39;s actions, so that the robot could adapt better to what it is expected. Note that prediction enables robots to also monitor processes. When the perceived situation differs from the expected one, it means that either our knowledge is not complete or something did not go as it was supposed to. In the former case, it would be possible to store the facts in memory for posterior learning, in the later case, an alarm or error could be triggered. In the example, the robot could detect a malfunctioning in the conveyor if the pieces stopped arriving close to the robot&#39;s workspace. </p>
              <a role="button" class="more collapsed" data-toggle="collapse" href="#cog-pred" aria-expanded="false" aria-controls="cog-pred"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#cog-pred-pubs" aria-expanded="false" aria-controls="cog-pred-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="cog-pred-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Tenorth, Moritz and Michael Beetz (2012). A unified representation for reasoning about robot actions, processes, and their effectson objects. In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, pp. 1351-1358
                    <a href="#KnowRob-card">KnowRob</a>
                </li>

              </ul>
            </div>
          </div><br>

          <div class="card w-100" id="cog-prob-card">
            <div class="card-body">
              <h5 class="card-title">Problem Solving and Planning</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">Card subtitle</h6> -->
              <p class="card-text collapse" id="cog-prob" aria-expanded="false">In novel situations where robots are meant to achieve their goals, it is necessary for them to be able to plan and solve problems. For the purpose of generating a plan, the robot needs a model of the environment utilized to predict the effects of its actions. Furthermore, the cognitive architecture must be able to represent a plan as an (at least partially) ordered set of actions, their expected effects, and the manner in which these effects enable subsequent actions. Sometimes, a robot could have a memory with previous plans which could be re-used with and without further modifications. Note that it is also considered the case of having conditional actions and different branches which depend on the outcome of previous events. Despite often being viewed intimately related, planning is somewhat less general than problem solving. In particular, the former usually refers to cognitive activities within the robot&#39;s head, whereas the later can also occur in the world. Concretely, when a problem to be solved is complex and the available memory is limited, a robot may search for solutions by executing actions in the environment, rather than constructing a complete internal plan. As an illustration, a collaborative robot could solve a problem by mixing the execution of actions such as &#39;asking for operator&#39;s help&#39; (external behavior) and the generation of actions&#39; sequences (internal planning).</p>
              <a role="button" class="more collapsed" data-toggle="collapse" href="#cog-prob" aria-expanded="false" aria-controls="cog-prob"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#cog-prob-pubs" aria-expanded="false" aria-controls="cog-prob-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="cog-prob-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Tenorth, Moritz and Michael Beetz (2012). A unified representation for reasoning about robot actions, processes, and their effectson objects. In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, pp. 1351-1358
                    <a href="#KnowRob-card">KnowRob</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Beßler, Daniel, Mihai Pomarlan, and Michael Beetz (2018). OWL-enabled Assembly Planningfor Robotic Agents. In: Proceedings of the 2018 International Conference on Autonomous Agents. AAMAS &#39;18. Finalist for the Best Robotics Paper Award. Stockholm, Sweden.
                    <a href="#KnowRob-card">KnowRob</a>
                </li>

              </ul>
            </div>
          </div><br>

          <div class="card w-100" id="cog-reas-card">
            <div class="card-body">
              <h5 class="card-title">Reasoning and Belief Maintenance</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">Card subtitle</h6> -->
              <p class="card-text collapse" id="cog-reas" aria-expanded="false">Reasoning is a cognitive activity which allows a robot to expand its knowledge state, drawing conclusions from other beliefs or assumptions the robot already maintains. Thus, it is required the existence of a representation of beliefs and the relationships among them. A common formalism used to encode such knowledge is first-order logic (FOL). Ontologies are often written in languages based on less expressive formalisms than FOL (e.g. OWL-description logic) in order to reduce the computational cost of inference. These formalisms, allow the use of different sorts of reasoning such as: deductive or inductive. For the robot of the previous example, it would be possible to infer how operators will react to unexpected interactions by knowing general information about human-robot interaction (deductive). Or the opposite, from specific operator&#39;s behaviors, inferring the norms to follow during human-robot interaction (inductive). Note that reasoning is not only relevant to infer new beliefs but also to decide whether to hold existing ones (belief maintenance). Such belief maintenance is especially important for dynamic environments in which situations may change in unexpected ways, with implications for the robot&#39;s behavior.</p>
              <a role="button" class="more collapsed" data-toggle="collapse" href="#cog-reas" aria-expanded="false" aria-controls="cog-reas"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#cog-reas-pubs" aria-expanded="false" aria-controls="cog-reas-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="cog-reas-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Warnier, Mathieu et al. (2012). When the robot puts itself in your shoes. Managing and exploiting human and robot beliefs. In: International Symposium on Robot and Human Interactive Communication (RO-MAN). IEEE, pp. 948-954.
                    <a href="#ORO-card">ORO</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Beßler, Daniel, Mihai Pomarlan, and Michael Beetz (2018). OWL-enabled Assembly Planningfor Robotic Agents. In: Proceedings of the 2018 International Conference on Autonomous Agents. AAMAS &#39;18. Finalist for the Best Robotics Paper Award. Stockholm, Sweden.
                    <a href="#KnowRob-card">KnowRob</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Tenorth, Moritz, Lars Kunze, et al. (2010). KNOWROB-MAP - Knowledge-LinkedSemantic Object Maps. In:10th IEEE-RAS International Conference on Humanoid Robots. Nashville, TN, USA, pp. 430-435.
                    <a href="#KnowRob-card">KnowRob</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Diab, Mohammed, Aliakbar Akbari, Muhayy Ud Din, et al. (2019). PMK-A Knowledge Processing Framework for Autonomous Robotics Perception and Manipulation. In: Sensors. 19. 5.
                    <a href="#PMK-card">PMK</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Bruno, Barbara, Carmine Tommaso Recchiuto, et al. (2019). Knowledge Representation for Culturally Competent Personal Robots: Requirements, Design Principles, Implementation, and Assessment. In: International Journal of Social Robotics11.3, pp. 515-538.
                    <a href="#CARESSES-card">CARESSES</a>
                </li>

              </ul>
            </div>
          </div><br>

          <div class="card w-100" id="cog-exec-card">
            <div class="card-body">
              <h5 class="card-title">Execution and Action</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">Card subtitle</h6> -->
              <p class="card-text collapse" id="cog-exec" aria-expanded="false">Cognition takes place to support and drive activity in the environment. To this end, a cognitive architecture must be able to represent and store motor skills that enable such activity. In the example, a collaborative robotic arm should have skills or policies for manipulating its surroundings and for collaborating with other agents (e.g. humans). A robot should also be able to execute those skills and actions in the environment, what can happen in a reactive form. Nevertheless, a cognitive architecture should enable a robot to maintain a continuum loop of execution. Hence, the robot would be able to interpret how the execution of actions is affecting the state of the environment and could adapt its behavior. A proper representation of the ongoing actions occurring in the environment, is essential for aspects related to robot action execution: robot adaptation, new skills learning, action-execution-related knowledge, etc. </p>
              <a role="button" class="more collapsed" data-toggle="collapse" href="#cog-exec" aria-expanded="false" aria-controls="cog-exec"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#cog-exec-pubs" aria-expanded="false" aria-controls="cog-exec-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="cog-exec-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Beetz, Michael, Lorenz Mosenlechner, and Moritz Tenorth (2010). CRAM - A Cognitive RobotAbstract Machine for everyday manipulation in human environments. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE,pp. 1012-1017.
                    <a href="#KnowRob-card">KnowRob</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Tenorth, Moritz, Georg Bartels, and Michael Beetz (2014). Knowledge-based Specification of Robot Motions. In: Proc. of the European Conference on Artificial Intelligence (ECAI).
                    <a href="#KnowRob-card">KnowRob</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Tenorth, Moritz, Daniel Nyga, and Michael Beetz (2010). Understanding and ExecutingInstructions for Everyday Manipulation Tasks from the World Wide Web. In: IEEE International Conference on Robotics and Automation (ICRA). Anchorage, AK, USA, pp. 1486-1491.
                    <a href="#KnowRob-card">KnowRob</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Goncalves, Paulo JS and Pedro MB Torres (2015). Knowledge representation applied to robotic orthopedic surgery. In: Robotics and Computer-Integrated Manufacturing. 33, pp. 90-99.
                    <a href="#OROSU-card">OROSU</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Sgorbissa, Antonio et al. (2018). Encoding guidelines for a culturally competent robot for elderly care. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, pp. 1988-1995
                    <a href="#CARESSES-card">CARESSES</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Stenmark, Maj, Jacek Malec, and Andreas Stolt (2015). From high-level task descriptions toexecutable robot code. In: Intelligent Systems. Springer, pp. 189-202.
                    <a href="#ROSETTA-card">ROSETTA</a>
                </li>

              </ul>
            </div>
          </div><br>

          <div class="card w-100" id="cog-inter-card">
            <div class="card-body">
              <h5 class="card-title">Interaction and Communication</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">Card subtitle</h6> -->
              <p class="card-text collapse" id="cog-inter" aria-expanded="false">Sometimes, the most effective way for a robot to obtain knowledge is from another agent (e.g. humans, robots, etc.), making communication another important ability that an architecture should support. Going back to the example used before, a collaborative robot could request for further information about how to perform a task or which are the preferences of the specific plant operator about where to place the picked pieces. Regardless of the modality or mean of communication, there should be a way to represent the transferred knowledge so that it is accessible to and understandable for the robot. Indeed, this should be bi-directional, meaning the robot must be able to transform stored knowledge into the concrete medium through which it will be communicated. </p>
              <a role="button" class="more collapsed" data-toggle="collapse" href="#cog-inter" aria-expanded="false" aria-controls="cog-inter"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#cog-inter-pubs" aria-expanded="false" aria-controls="cog-inter-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="cog-inter-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Ros, Raquel et al. (2010). Which one? grounding the referent based on efficient human-robot interaction. In: International Symposium in Robot and Human Interactive Communication (RO-MAN). IEEE, pp. 570-575.
                    <a href="#ORO-card">ORO</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Lemaignan, Severin, Raquel Ros, Rachid Alami, et al. (2011). What are you talking about? grounding dialogue in a perspective-aware robotic architecture. In: International Symposium on Robot and Human Interactive Communication (RO-MAN). IEEE, pp. 107-112.
                    <a href="#ORO-card">ORO</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Yazdani, Fereshta et al. (2018). Cognition-enabled Framework for Mixed Human-Robot Rescue Team. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE. Madrid, Spain.
                    <a href="#KnowRob-card">KnowRob</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Bruno, Barbara, Carmine Tommaso Recchiuto, et al. (2019). Knowledge Representation for Culturally Competent Personal Robots: Requirements, Design Principles, Implementation, and Assessment. In: International Journal of Social Robotics11.3, pp. 515-538.
                    <a href="#CARESSES-card">CARESSES</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Bruno, Barbara, Roberto Menicatti, et al. (2018). Culturally-Competent Human-Robot Verbal Interaction. In: International Conference on Ubiquitous Robots (UR). IEEE,pp. 388-395.
                    <a href="#CARESSES-card">CARESSES</a>
                </li>

              </ul>
            </div>
          </div><br>

          <div class="card w-100" id="cog-remem-card">
            <div class="card-body">
              <h5 class="card-title">Remembering, Reflection, and Learning</h5>
              <!-- <h6 class="card-subtitle mb-2 text-muted">Card subtitle</h6> -->
              <p class="card-text collapse" id="cog-remem" aria-expanded="false">There are some capabilities which cut across those described before, whose use could enhance the performance of autonomous robots while not being strictly necessary for robot autonomy: remembering, reflection and learning. Remembering is the ability to encode and store the results (facts) of cognitive tasks so that they can be retrieved later. Once again, based on the previous example, a collaborative robot could store the results of an entire day of work (e.g. successful experiences, human-robot interactions, etc.). On the other hand, reflection stands for the serious thought or consideration about something which usually is represented and stored in memory and can be retrieved. A collaborative robot could take into account a stored memory in order to explain which was the rationale behind its actions. Finally, learning, which usually involves generalization beyond specific beliefs and events. In the example, the collaborative robot would use the stored memories about successful and failed actions to generalize and learn from them. The knowledge used to learn might come from distinct sources, the observation of another agent, the result of previous experiences, or through kinesthetic teaching. No matter the source of experience, all of them require the existence of a memory in which the experiences are represented.</p>
              <a role="button" class="more collapsed" data-toggle="collapse" href="#cog-remem" aria-expanded="false" aria-controls="cog-remem"></a><br>
              <a role="button" class="card-link pubs collapsed" data-toggle="collapse" href="#cog-remem-pubs" aria-expanded="false" aria-controls="cog-remem-pubs"></a><br>
              <ul class="list-group list-group-flush collapse" id="cog-remem-pubs" aria-expanded="false">

                <li class="list-group-item font-weight-light font-italic text-muted">Beetz, Michael, Daniel Beßler, Andrei Haidu, et al. (2018). KnowRob 2.0 - A 2nd Generation Knowledge Processing Framework for Cognition-enabled Robotic Agents. In: IEEE International Conference on Robotics and Automation (ICRA).
                    <a href="#KnowRob-card">KnowRob</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Beetz, Michael, Moritz Tenorth, and Jan Winkler (2015). Open-EASE - A Knowledge Processing Service for Robots and Robotics/AI Researchers. In: IEEE International Conference on Robotics and Automation (ICRA). Finalist for the Best Cognitive Robotics Paper Award. Seattle, Washington, USA.
                    <a href="#KnowRob-card">KnowRob</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Stenmark, Maj, Mathias Haage, et al. (2018). Supporting semantic capture during kinestheticteaching of collaborative industrial robots. In: International Journal of Semantic Computing. 12.01, pp. 167-186.
                    <a href="#ROSETTA-card">ROSETTA</a>
                </li>

                <li class="list-group-item font-weight-light font-italic text-muted">Topp, Elin A et al. (2018). Ontology-Based Knowledge Representation for Increased Skill Reusability in Industrial Robots. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, pp. 5672-5678.
                    <a href="#ROSETTA-card">ROSETTA</a>
                </li>

              </ul>
            </div>
          </div><br>

        </div>
      </div>
    </div>
  </section>

  <section id="contact">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2>Contact us</h2>
          <p class="lead">Should you have any doubt/comment about our work, please, do not hesitate to contact us.
          <br>
          <br>Alberto Olivares-Alarcos - <a href="url">aolivares@iri.upc.edu</a> 
          <br>Daniel Be&szligler - <a href="url">danielb@uni-bremen.de</a></p>
        </div>
      </div>
    </div>
  </section>

  <!-- Footer -->
  <footer class="py-5 bg-dark">
    <div class="container">
      <p class="m-0 text-center text-white">Copyright &copy; 2020</p>
    </div>
    <!-- /.container -->
  </footer>

  <script>
(function($) {
  "use strict"; // Start of use strict

  // Smooth scrolling using jQuery easing
  $('a.js-scroll-trigger[href*="#"]:not([href="#"])').click(function() {
    if (location.pathname.replace(/^\//, '') == this.pathname.replace(/^\//, '') && location.hostname == this.hostname) {
      var target = $(this.hash);
      target = target.length ? target : $('[name=' + this.hash.slice(1) + ']');
      if (target.length) {
        $('html, body').animate({
          scrollTop: (target.offset().top - 56)
        }, 1000, "easeInOutExpo");
        return false;
      }
    }
  });

  // Closes responsive menu when a scroll trigger link is clicked
  $('.js-scroll-trigger').click(function() {
    $('.navbar-collapse').collapse('hide');
  });

  // Activate scrollspy to add active class to navbar items on scroll
  $('body').scrollspy({
    target: '#mainNav',
    offset: 56
  });

})(jQuery); // End of use strict
  </script>

</body>

</html>

